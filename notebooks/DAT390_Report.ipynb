{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cancer is a deadly disease, which is responsible for over 9 millions death in 2018 \\cite{wth}. Therefore, it is crucial to find the effective and efficient treatments. One of the most effective cancer treatments is radiotherapy, where cancer cells are killed using doses of radiation. However, the irradiation process also affects healthy tissues surrounding the cancer tumour. Thus, accuracy in radiotherapy has to be increased to minimise the radiation dose delivered to healthy cells and maximise the dose to cancer tumour. A study by \\citet{Njeh} describes the steps in radiotherapy as links in a chain, in which the weakest link will decide the accuracy of radiotherapy. \\citet{Njeh}'s study shows that tumour delineation is the weakest link, and therefore has significant impacts in radiotherapy treatments.\n",
    "\n",
    "- waiting time\n",
    "- interobserver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Why is delineation of tumours important?\n",
    "- How is delineation done today?\n",
    "- What uncertainties are involved?\n",
    "- CNNs for auto-delineation of tumours\n",
    "- Propose solution - goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This report will define a software requirement specification (SRS) and Design Document of a Keras-based framework for automatic delineation of cancer tumours. Besides, the progress of the development based on the SRS and Design as well as the current results are also included."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theory and Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolution Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Define CNN here\n",
    "- Remember to mention:\n",
    "  - Model\n",
    "  - Layers\n",
    "  - Briefly describe CONV, how does it apply to image\n",
    "  - Activation function\n",
    "  - Loss\n",
    "  - Optimizer\n",
    "  - Scheduler?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## U-Net Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The development of the resulted framework, named *deoxys*, has the goal of providing the users the ability to run multiple experiments of different CNN models and then choose the best model for final prediction. This framework should be specialized in deep-learning in medical images, especially in auto-delineation of cancer tumour. Because of that, it should integrate u-net architecture and image preprocessing modules, as well as logging tools and performance visualization tools when running experiments. These are the minimum requirements of the framework. It can be later extended with other types of architectures, preprocessors, automation, interactive verbose configuration and visualization.\n",
    "\n",
    "Planned development time as long as maintenance time will be continuously from October 1st, 2019 until May 1st, 2020. The first milestone is on January 6th, 2020, with the goal of creating a framework that satisfies the minimum requirements, which will be defined in detail in the software requirement specification (see \\ref{software-requirement-specification})."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software Requirement Specification\n",
    "\n",
    "This part defines the requirement specification of the developing framework. Because of that, terms indicating future-tense such as \"should\", \"shall\", \"will\" as well as terms indicating ability such as \"can\", \"may\" will be used when describing framework.\n",
    "\n",
    "In order to reach the goal of the development, the *deoxys* framework should satisfy all the requirements defined in User Requirement Specification (see \\ref{user-requirement-specification}) and System Requirement Specification (see \\ref{system-requirement-specification})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User Requirement Specification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users are referring to master students, PhD candidates, researchers and anyone who wants to use deep-learning on automatic delineation of cancer tumors.\n",
    "This framework is targeted to the users with basic programming knowledge, including the usage of JSON data structure, and with the knowledge of deep learning, especially in convolution neural network. Basic programming knowledge is including but not limited to object-oriented programming in python, other python libraries such as matplotlib, keras, h5py."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the help of *deoxys*, users shall have the ability to perform multiple CNN experiments by creating configurable JSON files. Users can define their own sequential or u-net model with the choices of layers, loss functions, optimizers, metrics and many other hyper-parameters. In addition, users can choose how to split the data for training, validation and testing. Each experiment should include training the data, logging the performance and evaluation of trained model on test data. All trained models can be saved to disk and loaded back for continuation of training or any other purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a follow-up after running an experiment, users can also check the predicted outputs as delineated images in comparison with the original image and view the performance graphs of the trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users with advanced programming knowledge can also customize and create their custom model architecture, layers, activation functions, loss functions, optimizers, metrics, etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the user requirement specification, the *deoxys* framework should support the following 5 use cases:\n",
    "\n",
    "1. Create a model\n",
    "1. Train a model\n",
    "1. Save a trained model\n",
    "1. Load a model from file(s)\n",
    "1. Create and apply customized model objects to the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use case diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Figure \\ref{fig:usecase} shows the all the use cases and their interaction inside the framework. There are three main flows of the use cases:\n",
    "\n",
    "- Setup experiment using configurations to run and evaluate experiment. This starts with creating a model from configuration, then setting up experiment by training and evaluating the configured model.\n",
    "- Load and save trained model from and to disk. \n",
    "- Create customize objects / elements for the experiment. This includes: Layers, Activation functions, Loss functions, Optimizers, Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{figure*}[h!]\n",
    "  \\includegraphics[width=\\textwidth]{img/use_case.png}\n",
    "  \\caption{Use Case Diagram}\n",
    "  \\label{fig:usecase}\n",
    "\\end{figure*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use case 1: Create a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Every actions of the user involves the use of the model. The model term in the *deoxys* framework refers to a group of the three components. \n",
    "The first component is a convolution neural network. It can be a sequential CNN or an U-net CNN, or even a customized CNN defined by the users. This neural network contains input shapes, layers, activation functions. We call this component the architecture of the model. \n",
    "The second component is the set of hyper-parameters of the neural network, which includes the optimizers, loss function, and metrics. \n",
    "To train and evaluate a neural network, the data - medical images with delineation contour should \n",
    "The last component, called Data Reader, acts as a data provider, which feed the data into the neural network for training and evaluation. This involves splitting up the data into  A typical way of spitting the data in machine learning is to split the data into training data, validation data, and test data. Training data is used for training the model, while validation data is used for checking the quality of the model. Test data is usually the data the model need to test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use case 2: Train a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use case 03: Create customize objects / elements for the experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1: Create new customized objects\n",
    "\n",
    "Step 2: Register the created objects to the framework. System Check for validity of the object, raise an exception if the object is failed to register\n",
    "\n",
    "Step 3: Create an experiment using the newly create objects. System Perform the experiment without error using the new objects\n",
    "\n",
    "Step 4: View the output from files or diagram (depending on the configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### System Requirement Specification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *deoxys* framework should have the following attributes: usability, reliability, flexibility, maintainability and portability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Usability\n",
    "The *deoxys* framework should be easy to install, learn and use. The expected training and learning time for a user to use this framework effectively should not take more than 40 hours. For this reason, this framework should have a detailed documentation of installation guide and usage of each class, function and property. It should also provide sample code snippets which can be applied to the defined use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reliability\n",
    "The output generated when running code from *deoxys* framework should have the behaviors as documented. In addition, the unexpected error rate should be under 5% and at least 80% of code lines should have been tested before release."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Flexibility\n",
    "User should be able to customize and create new components to integrate in *deoxys* framework."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Maintainability\n",
    "The *deoxys* framework should be easy to maintain. Therefore, it should be divided into separated modules. Moreover, all of the source code should follow the PEP8 coding convention. Also, this framework should log all actions in different versions and issues from the users.\n",
    "\n",
    "Maintaining the framework includes fixing bugs, handling issues, updating and adding new features. The maintaining activities should last at least until May 2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Portability\n",
    "The *deoxys* framework should work properly when the following hardware requirements and environment are satisfied:\n",
    "\n",
    "- System memory: at least 8GB with GPU or 13GB without GPU\n",
    "- Python version: at least 3.7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Designs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before development, the designs of the framework have to be considered.\n",
    "\n",
    "The first things to concern are the usability and maintainability of the framework. As stated, in the previous sessions, all source code shall follow PEP8 coding convention. Sphinx will be used as the tool of documentation. In addition, git is used as a tool to handle logging and version management. All source code should be available in github.com/huynhngoc/deoxys.\n",
    "\n",
    "Implementation all layers and other components in convolution neural network within three-month time is impossible. Therefore, keras is used as a based library, as it contains implemented layers, activation functions, optimizers and other components in CNN. Also, keras is compatible with tensorflow 1.x, 2.x, which is a very powerful backend tool in deep-learning, as well as other backend suchs as Theano, etc...\n",
    "\n",
    "Finally, this report suggests that the framework should have the following modules:\n",
    "- Models: contains a wrapper of a keras model. Other keras objects such as optimizers, activation functions.. are also included.\n",
    "- Infrastructure and configuration loader\n",
    "- Data reader: Since the target of this framework are medical images, the input data are often large in size and usually cannot fit into the computer memory. In order to avoid out of memory errors, this module should contain a data generator that split image data into smaller batches that can fit into the memory when training the model.\n",
    "- Experiment:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using keras, why?\n",
    "  - Implemented layers, activation function, optimizers ...\n",
    "  - Compability with tensorflow 1.x, 2+, multiple backend\n",
    "- Coding convention:\n",
    "  - PEP8\n",
    "  - pydoc\n",
    "- Structure\n",
    "  - Model:\n",
    "  - Infrastructure / config loader\n",
    "  - Data reader:\n",
    "     - Generators: why need it (batching data)\n",
    "     - Preprocessors\n",
    "  - experiment:\n",
    "     - Single: logging and performance and plot result\n",
    "     - Multi: choose best model\n",
    "     \n",
    "     Explain why i use this structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structure diagram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/project_structure.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These modules are the components creating a model. They are layers, loss functions, activation functions, metrics, optimizer and callbacks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, this module should be a wrapper of a keras model. As a result, it should have methods of the keras model such as:\n",
    "\n",
    "- `load`: loading model\n",
    "- `save`: save model to file\n",
    "- `fit`: fit a model with data\n",
    "- `predict`: predict the target\n",
    "- `evaluate`: evaluate the performance of the current state of the model\n",
    "\n",
    "Secondly, it should have a Data Reader (see \\ref{data-reader}) instance, which provided proper inputs for actions on the model.\n",
    "\n",
    "Finally, by performing method in keras model using the inputs from the data reader, the model should have the following methods:\n",
    "\n",
    "- `fit_train`: fit the training data\n",
    "- `predict_val`: predict the validation data\n",
    "- `predict_test`: predict the test data\n",
    "- `evaluate_test`: evaluate the performance of the current state of the model on the test data\n",
    "\n",
    "Training data, validation data, test data are explained in \\ref{data-reader}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Infrastructure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module should have a function to create a model from one of the predefined structures. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data reader module should provide input data for training and evaluating the model. A typical way of spitting the data in machine learning is to split the data into training data, validation data, and test data. Training data is used for training the model, while validation data is used for checking the quality of the model. Test data is usually the data the model need to test. To use the method of splitting, the data reader should provide three sets of data: training data, validation data, test data. These three sets should be in the form of a python generator, which is wrapped into a Data Generator. Using a python generator is essential because medical image data usually has large size, and may not be able to fit into the running environment's memory. Using a python generator will feed the model with small part of the data and minimize the chance of getting out of memory error. List of preprocessors to be applied on the data should be configurable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HDF5 Data Reader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`h5` or `hdf5` is a file format that has the ability to store large dataset with compression and hierarchy, as well as meta-data. The main components of an HDF5 file are groups and datasets, where datasets are pieces of data that is stored in file while groups are containers of datasets.\n",
    "\n",
    "The *deoxys* framework should have a HDF5 Data Reader, which is a Data Reader that process data from a hdf5 file. As a result, it should provide the three datasets: train, validation and test. In addition, since an HDF5 file can be splitted into groups, the HDF5 Data Reader should provide an aid for configure which groups of data to be in the 3 basic sets. It should be easy to configure different group into different purpose for cross-validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explain the json structure, note the require keywords\n",
    "- Why it's easy to setup experiment\n",
    "- Example of setting up experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Completed modules\n",
    "\n",
    "By the time this report is submitted, users can perform a single experiment, with saving, loading, and visualization using the *deoxys* framework. This means that, all parts but \"multiple experiments\" from the design diagram in figure ~\\ref{fig:design} have been implemented."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In-progress modules\n",
    "Modules related to running multiple experiments are still in development. There are problems involving the process of combining multiple single experiments into a batch of experiments, as well as the concurrent programming that allows to run multiple experiments in parallel.\n",
    "\n",
    "Besides, there are still lack of tests and documentations that needs to be resolved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run on test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data from Oslo University hospital is used for running a test experiment. The model parameters are taken from Yngve Mardal Moe's master thesis (\\cite{}) and run the training set with only 3000 slices of images.\n",
    "\n",
    "The result was amazing as the dice is about 0.5 (graph, output log). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Advantages:\n",
    "- Disadvantages:\n",
    "- Improvement:\n",
    "  - What should be added more (Preprocessor, Callbacks, ....)\n",
    "  - Auto-generate config tool (web-base)\n",
    "  - Back-propagation implementation based on implemented model\n",
    "  - Visualize progress of training / prediction\n",
    "  - Datagenerator as sequential model for multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reference List**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- M Jameson, L Holloway, P Vial, S Vinod, P Metcalfe. 2010. A review of methods of analysis in contouring studies for radiation oncology. Journal of Medical Imaging and Radiation Oncology 54:401-410. Note: Understand the basics for your introduction:\n",
    "\n",
    "\"There is no consistent or widely accepted method of\n",
    "systematic contour comparison. A number of contouring\n",
    "metrics exist; some of which are available in treatment\n",
    "planning systems and others require specialised software. \"\n",
    "\n",
    "\"Volume was the most frequently used metric\n",
    "across all tumour sites. Shape/dimension was the next\n",
    "most frequently used metric in all tumour sites except for\n",
    "brain and head and neck, where COV and CI were the\n",
    "next most frequent metrics, respectively\"\n",
    "\n",
    "\"the choice of metrics in many studies is\n",
    "somewhat arbitrary and not determined on any established clinical basis. Further studies are needed to assess\n",
    "the advantages and disadvantages of each metric in\n",
    "various situations\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- C Njeh. 2008. Tumor delineation: The weakest link in the search for accuracy in radiotherapy. Journal of Medical Physics 33:136-140. Note: Understand the basics for your introduction [link](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2772050/)\n",
    "\n",
    "Use Figure 1: Some of the steps in radiotherapy that can be represented by links in a chain; treatment accuracy will be limited by the weakest link in the chain\"\n",
    "\n",
    "Use Figure 3\n",
    "Illustration of the effect of high conformal radiation therapy and geometric miss due to delineation\n",
    "\n",
    "\"It is evident that tumor delineation is currently the weakest link in radiotherapy accuracy and will continue to have a significant impact until improvement in tumor delineation is achieved. With the advancement of computer programming and imaging technology, especially functional imaging using PET, there is a possibility of converging and making tumor identification and definition less subjective and less observer-dependent.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2457\n"
     ]
    }
   ],
   "source": [
    "import io\n",
    "from IPython.nbformat import current\n",
    "\n",
    "with io.open('DAT390_Report.ipynb', 'r', encoding='utf-8') as f:\n",
    "    nb = current.read(f, 'json')\n",
    "\n",
    "word_count = 0\n",
    "for cell in nb.worksheets[0].cells:\n",
    "    if cell.cell_type == \"markdown\":\n",
    "        word_count += len(cell['source'].replace('#', '').lstrip().split(' '))\n",
    "print(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
